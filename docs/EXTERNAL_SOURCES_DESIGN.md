# å¤–éƒ¨ã‚µã‚¤ãƒˆé€£æºãƒ»ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ç®¡ç†è¨­è¨ˆ

## ğŸ“‹ æ¦‚è¦

åŸºç¤ãƒ‡ãƒ¼ã‚¿ï¼ˆGMAPãƒ»å…¬å¼ã‚µã‚¤ãƒˆï¼‰ã‚’å…ƒã«ã€å¤–éƒ¨ã‚µã‚¤ãƒˆæƒ…å ±ã‚’ä½“ç³»çš„ã«è‚‰ä»˜ã‘ã™ã‚‹ä»•çµ„ã¿ã€‚
Indeedã€ãƒ›ãƒƒãƒˆãƒšãƒƒãƒ‘ãƒ¼ã€é£Ÿã¹ãƒ­ã‚°ãªã©ã€è¤‡æ•°ã®å¤–éƒ¨ã‚µã‚¤ãƒˆã‚’çµ±ä¸€çš„ã«ç®¡ç†ã€‚

---

## ğŸ—ï¸ ãƒ‡ãƒ¼ã‚¿æ§‹é€ è¨­è¨ˆ

### 1. ExternalSourceï¼ˆå¤–éƒ¨ã‚µã‚¤ãƒˆå®šç¾©ãƒã‚¹ã‚¿ï¼‰

```python
# models.py

class ExternalSource(db.Model):
    """å¤–éƒ¨ã‚µã‚¤ãƒˆå®šç¾©ãƒã‚¹ã‚¿"""
    __tablename__ = 'external_source'
    
    id = db.Column(db.Integer, primary_key=True)
    
    # åŸºæœ¬æƒ…å ±
    name = db.Column(db.String(100), nullable=False, unique=True)
    # ä¾‹: 'Indeed', 'Hot Pepper Beauty', 'Tabelog', 'ãƒªã‚¸ãƒ§ãƒ–'
    
    slug = db.Column(db.String(50), nullable=False, unique=True)
    # ä¾‹: 'indeed', 'hotpepper', 'tabelog'
    
    url_pattern = db.Column(db.String(500), nullable=True)
    # ä¾‹: 'https://jp.indeed.com/cmp/{company_id}'
    
    icon_url = db.Column(db.String(500), nullable=True)
    # ã‚µã‚¤ãƒˆã‚¢ã‚¤ã‚³ãƒ³URL
    
    # åˆ†é¡
    category = db.Column(db.String(50), nullable=False)
    # 'job', 'review', 'booking', 'media', 'sns'
    
    # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°è¨­å®š
    search_url_template = db.Column(db.String(500), nullable=True)
    # ä¾‹: 'https://jp.indeed.com/jobs?q={business_name}+{location}'
    
    scraping_enabled = db.Column(db.Boolean, default=True)
    scraping_interval_days = db.Column(db.Integer, default=30)
    # å†ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°é–“éš”ï¼ˆæ—¥æ•°ï¼‰
    
    # å–å¾—ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å®šç¾©ï¼ˆJSONï¼‰
    extractable_fields = db.Column(db.JSON, nullable=True)
    # ä¾‹: {"æ±‚äººæ•°": "integer", "å¹³å‡è©•ä¾¡": "float", "æ²è¼‰ãƒšãƒ¼ã‚¸URL": "string"}
    
    # ãƒ¡ã‚¿æƒ…å ±
    is_active = db.Column(db.Boolean, default=True)
    priority = db.Column(db.Integer, default=0)  # å„ªå…ˆåº¦ï¼ˆé«˜ã„é †ã«å‡¦ç†ï¼‰
    notes = db.Column(db.Text, nullable=True)
    created_at = db.Column(db.DateTime, default=datetime.utcnow)
    
    # ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    external_links = db.relationship('ExternalLink', backref='source', 
                                    lazy=True, cascade="all, delete-orphan")


class ExternalLink(db.Model):
    """Business Ã— ExternalSource ã®é€£æºæƒ…å ±"""
    __tablename__ = 'external_link'
    
    id = db.Column(db.Integer, primary_key=True)
    
    # é–¢é€£ä»˜ã‘
    business_id = db.Column(db.Integer, db.ForeignKey('business.id'), nullable=False)
    source_id = db.Column(db.Integer, db.ForeignKey('external_source.id'), nullable=False)
    
    # URLæƒ…å ±
    url = db.Column(db.String(500), nullable=False)
    # ä¾‹: 'https://jp.indeed.com/cmp/â—‹â—‹ã‚¯ãƒªãƒ‹ãƒƒã‚¯'
    
    # å–å¾—ãƒ‡ãƒ¼ã‚¿ï¼ˆJSONï¼‰
    scraped_data = db.Column(db.JSON, nullable=True)
    # ä¾‹: {"æ±‚äººæ•°": 5, "å¹³å‡è©•ä¾¡": 4.2, "ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°": 18}
    
    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
    status = db.Column(db.String(20), default='active')
    # 'active', 'inactive', 'error', 'pending'
    
    # ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å±¥æ­´
    last_scraped_at = db.Column(db.DateTime, nullable=True)
    last_scrape_status = db.Column(db.String(50), nullable=True)
    # 'success', 'failed', 'not_found', 'blocked'
    
    error_message = db.Column(db.Text, nullable=True)
    scrape_count = db.Column(db.Integer, default=0)
    
    # ãƒ¡ã‚¿æƒ…å ±
    created_at = db.Column(db.DateTime, default=datetime.utcnow)
    updated_at = db.Column(db.DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    
    # ãƒ¦ãƒ‹ãƒ¼ã‚¯åˆ¶ç´„
    __table_args__ = (
        db.UniqueConstraint('business_id', 'source_id', name='_business_source_link_uc'),
        db.Index('idx_external_link_source', 'source_id', 'status'),
    )


# Business ãƒ¢ãƒ‡ãƒ«ã«è¿½åŠ 
class Business(db.Model):
    # ... æ—¢å­˜ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
    
    # å¤–éƒ¨ã‚µã‚¤ãƒˆãƒªãƒ³ã‚¯
    external_links = db.relationship('ExternalLink', backref='business', 
                                    lazy=True, cascade="all, delete-orphan")


# ScrapingTask æ‹¡å¼µ
class ScrapingTask(db.Model):
    __bind_key__ = 'scraping'
    id = db.Column(db.Integer, primary_key=True)
    
    # æ‹¡å¼µ: å¤–éƒ¨ã‚µã‚¤ãƒˆã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¯¾å¿œ
    task_type = db.Column(db.String(30), nullable=True)
    # 'gmap_discovery', 'hpb_scraping', 'external_source_discovery', 'external_source_scraping'
    
    target_url = db.Column(db.String(500), nullable=True)
    search_keyword = db.Column(db.String(200), nullable=True)
    
    # æ–°è¦è¿½åŠ 
    external_source_id = db.Column(db.Integer, nullable=True)
    # ExternalSource.idï¼ˆå¤–éƒ¨é€£æºæ™‚ã®ã¿ä½¿ç”¨ï¼‰
    
    business_id = db.Column(db.Integer, nullable=True)
    # ç‰¹å®šãƒ“ã‚¸ãƒã‚¹ã¸ã®ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ï¼ˆbusiness_idæŒ‡å®šæ™‚ï¼‰
    
    status = db.Column(db.String(50), nullable=False, default='æœªå®Ÿè¡Œ')
    category_id = db.Column(db.Integer, nullable=False)
    last_run_at = db.Column(db.DateTime, nullable=True)
    
    # çµæœ
    result_summary = db.Column(db.JSON, nullable=True)
    # ä¾‹: {"found": 15, "new": 8, "updated": 7}
```

---

## ğŸ¯ å¤–éƒ¨ã‚µã‚¤ãƒˆå®šç¾©ä¾‹

### åˆæœŸç™»éŒ²ãƒ‡ãƒ¼ã‚¿

```python
# scripts/init_external_sources.py

EXTERNAL_SOURCES = [
    {
        'name': 'Indeed',
        'slug': 'indeed',
        'url_pattern': 'https://jp.indeed.com/cmp/{company_slug}',
        'category': 'job',
        'search_url_template': 'https://jp.indeed.com/jobs?q={business_name}+{location}&l={city}',
        'extractable_fields': {
            'æ±‚äººæ²è¼‰æ•°': 'integer',
            'ä¼æ¥­è©•ä¾¡': 'float',
            'å£ã‚³ãƒŸæ•°': 'integer',
            'çµ¦ä¸æƒ…å ±': 'string',
        },
        'icon_url': 'https://www.indeed.com/favicon.ico',
        'priority': 10,
    },
    {
        'name': 'ãƒªã‚¸ãƒ§ãƒ–',
        'slug': 'rejob',
        'url_pattern': 'https://relax-job.com/detail/{job_id}',
        'category': 'job',
        'search_url_template': 'https://relax-job.com/search?keyword={business_name}',
        'extractable_fields': {
            'æ±‚äººæ²è¼‰æ•°': 'integer',
            'è·ç¨®': 'string',
            'å‹¤å‹™åœ°': 'string',
        },
        'priority': 9,
    },
    {
        'name': 'ãƒ›ãƒƒãƒˆãƒšãƒƒãƒ‘ãƒ¼ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ¼',
        'slug': 'hotpepper',
        'url_pattern': 'https://clinic.beauty.hotpepper.jp/slnH{salon_id}/',
        'category': 'booking',
        'search_url_template': None,  # æ—¢å­˜HPBã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°åˆ©ç”¨
        'extractable_fields': {
            'å£ã‚³ãƒŸä»¶æ•°': 'integer',
            'å¹³å‡è©•ä¾¡': 'float',
            'ã‚¯ãƒ¼ãƒãƒ³æ•°': 'integer',
            'æ–½è¡“ãƒ¡ãƒ‹ãƒ¥ãƒ¼': 'list',
        },
        'priority': 8,
    },
    {
        'name': 'é£Ÿã¹ãƒ­ã‚°',
        'slug': 'tabelog',
        'url_pattern': 'https://tabelog.com/tokyo/{restaurant_id}/',
        'category': 'review',
        'search_url_template': 'https://tabelog.com/keywords/{business_name}/tokyo/',
        'extractable_fields': {
            'è©•ä¾¡': 'float',
            'å£ã‚³ãƒŸæ•°': 'integer',
            'ã‚¸ãƒ£ãƒ³ãƒ«': 'string',
            'äºˆç®—': 'string',
        },
        'priority': 7,
    },
    {
        'name': 'Twitter/X',
        'slug': 'twitter',
        'url_pattern': 'https://twitter.com/{screen_name}',
        'category': 'sns',
        'search_url_template': 'https://twitter.com/search?q={business_name}',
        'extractable_fields': {
            'ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°': 'integer',
            'ãƒ„ã‚¤ãƒ¼ãƒˆæ•°': 'integer',
            'æœ€çµ‚æ›´æ–°æ—¥': 'date',
        },
        'priority': 5,
    },
    {
        'name': 'Instagram',
        'slug': 'instagram',
        'url_pattern': 'https://www.instagram.com/{username}/',
        'category': 'sns',
        'search_url_template': None,  # æ¤œç´¢APIåˆ¶é™ã‚ã‚Š
        'extractable_fields': {
            'ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°': 'integer',
            'æŠ•ç¨¿æ•°': 'integer',
        },
        'priority': 5,
    },
]


def init_external_sources():
    """å¤–éƒ¨ã‚µã‚¤ãƒˆå®šç¾©ã‚’åˆæœŸåŒ–"""
    with app.app_context():
        for source_data in EXTERNAL_SOURCES:
            existing = ExternalSource.query.filter_by(slug=source_data['slug']).first()
            
            if not existing:
                source = ExternalSource(**source_data)
                db.session.add(source)
                print(f"âœ“ {source_data['name']} ã‚’è¿½åŠ ")
            else:
                print(f"- {source_data['name']} ã¯æ—¢ã«å­˜åœ¨")
        
        db.session.commit()
        print(f"\nå¤–éƒ¨ã‚µã‚¤ãƒˆç™»éŒ²å®Œäº†: {ExternalSource.query.count()}ä»¶")


if __name__ == '__main__':
    init_external_sources()
```

---

## ğŸ” Indeed ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè£…ä¾‹

### 1. æ¤œç´¢ãƒ»ç™ºè¦‹ãƒ•ã‚§ãƒ¼ã‚º

```python
# scripts/scrape_indeed.py

import sys
sys.path.append('/var/www/salon_app')

from app import app, db, Business, ExternalSource, ExternalLink, get_stealth_driver
from bs4 import BeautifulSoup
import time
import re

def discover_indeed_pages(business_id=None, limit=None):
    """
    Indeedã«æ²è¼‰ã•ã‚Œã¦ã„ã‚‹ä¼æ¥­ã‚’æ¤œç´¢ãƒ»ç™ºè¦‹
    
    Args:
        business_id: ç‰¹å®šãƒ“ã‚¸ãƒã‚¹ã®ã¿å‡¦ç†ï¼ˆNoneãªã‚‰å…¨ä»¶ï¼‰
        limit: å‡¦ç†ä»¶æ•°åˆ¶é™
    """
    api_key = os.environ.get('GOOGLE_MAPS_API_KEY')
    
    with app.app_context():
        # Indeed ã‚½ãƒ¼ã‚¹å–å¾—
        indeed_source = ExternalSource.query.filter_by(slug='indeed').first()
        if not indeed_source:
            print("ã‚¨ãƒ©ãƒ¼: Indeedã‚½ãƒ¼ã‚¹ãŒæœªç™»éŒ²")
            return
        
        # å¯¾è±¡ãƒ“ã‚¸ãƒã‚¹å–å¾—
        query = Business.query.filter_by(business_type='beauty_clinic')
        
        if business_id:
            query = query.filter_by(id=business_id)
        
        # æ—¢ã«Indeedãƒªãƒ³ã‚¯ãŒã‚ã‚‹ã‚‚ã®ã¯é™¤å¤–
        query = query.filter(
            ~Business.external_links.any(ExternalLink.source_id == indeed_source.id)
        )
        
        if limit:
            query = query.limit(limit)
        
        businesses = query.all()
        total = len(businesses)
        
        print(f"=== Indeedæ¤œç´¢é–‹å§‹ ===")
        print(f"å¯¾è±¡: {total}ä»¶")
        
        driver = get_stealth_driver()
        found = 0
        not_found = 0
        
        try:
            for i, business in enumerate(businesses, 1):
                print(f"\n[{i}/{total}] {business.name}")
                
                # Indeedæ¤œç´¢
                search_url = f"https://jp.indeed.com/jobs?q={business.name}&l=æ±äº¬éƒ½"
                driver.get(search_url)
                time.sleep(3)
                
                # ä¼æ¥­ãƒšãƒ¼ã‚¸ãƒªãƒ³ã‚¯ã‚’æ¢ã™
                soup = BeautifulSoup(driver.page_source, 'html.parser')
                
                # ä¼æ¥­åä¸€è‡´ãƒã‚§ãƒƒã‚¯
                company_links = soup.find_all('a', href=re.compile(r'/cmp/'))
                
                indeed_url = None
                for link in company_links:
                    company_name = link.get_text(strip=True)
                    
                    # åå‰ã®é¡ä¼¼åº¦ãƒã‚§ãƒƒã‚¯ï¼ˆç°¡æ˜“ï¼‰
                    if business.name in company_name or company_name in business.name:
                        indeed_url = 'https://jp.indeed.com' + link['href']
                        break
                
                if indeed_url:
                    # ExternalLinkä½œæˆ
                    external_link = ExternalLink(
                        business_id=business.id,
                        source_id=indeed_source.id,
                        url=indeed_url,
                        status='pending',
                        last_scrape_status='found'
                    )
                    db.session.add(external_link)
                    db.session.commit()
                    
                    print(f"  âœ“ ç™ºè¦‹: {indeed_url}")
                    found += 1
                else:
                    print(f"  - è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                    not_found += 1
                
                time.sleep(2)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
                
        finally:
            driver.quit()
        
        print(f"\n=== å®Œäº† ===")
        print(f"ç™ºè¦‹: {found}ä»¶")
        print(f"æœªç™ºè¦‹: {not_found}ä»¶")


def scrape_indeed_details():
    """
    ç™ºè¦‹æ¸ˆã¿Indeedãƒšãƒ¼ã‚¸ã‹ã‚‰è©³ç´°æƒ…å ±ã‚’å–å¾—
    """
    with app.app_context():
        indeed_source = ExternalSource.query.filter_by(slug='indeed').first()
        
        # status='pending' ã®ãƒªãƒ³ã‚¯ã‚’å–å¾—
        links = ExternalLink.query.filter_by(
            source_id=indeed_source.id,
            status='pending'
        ).all()
        
        total = len(links)
        print(f"=== Indeedè©³ç´°å–å¾—é–‹å§‹ ===")
        print(f"å¯¾è±¡: {total}ä»¶")
        
        driver = get_stealth_driver()
        success = 0
        failed = 0
        
        try:
            for i, link in enumerate(links, 1):
                business = link.business
                print(f"\n[{i}/{total}] {business.name}")
                print(f"  URL: {link.url}")
                
                try:
                    driver.get(link.url)
                    time.sleep(3)
                    
                    soup = BeautifulSoup(driver.page_source, 'html.parser')
                    
                    # ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
                    scraped_data = {}
                    
                    # æ±‚äººæ²è¼‰æ•°
                    jobs_section = soup.find('div', class_='cmp-Jobs-tab')
                    if jobs_section:
                        jobs_count_text = jobs_section.find('span', class_='cmp-navigation-label')
                        if jobs_count_text:
                            match = re.search(r'(\d+)', jobs_count_text.get_text())
                            if match:
                                scraped_data['æ±‚äººæ²è¼‰æ•°'] = int(match.group(1))
                    
                    # ä¼æ¥­è©•ä¾¡
                    rating_elem = soup.find('span', class_='cmp-Rating-text')
                    if rating_elem:
                        try:
                            scraped_data['ä¼æ¥­è©•ä¾¡'] = float(rating_elem.get_text())
                        except ValueError:
                            pass
                    
                    # å£ã‚³ãƒŸæ•°
                    reviews_elem = soup.find('div', class_='cmp-ReviewsCount')
                    if reviews_elem:
                        match = re.search(r'(\d+)', reviews_elem.get_text())
                        if match:
                            scraped_data['å£ã‚³ãƒŸæ•°'] = int(match.group(1))
                    
                    # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
                    link.scraped_data = scraped_data
                    link.status = 'active'
                    link.last_scraped_at = datetime.utcnow()
                    link.last_scrape_status = 'success'
                    link.scrape_count += 1
                    
                    db.session.commit()
                    
                    print(f"  âœ“ å–å¾—æˆåŠŸ: {scraped_data}")
                    success += 1
                    
                except Exception as e:
                    print(f"  âœ— ã‚¨ãƒ©ãƒ¼: {e}")
                    link.last_scrape_status = 'failed'
                    link.error_message = str(e)
                    db.session.commit()
                    failed += 1
                
                time.sleep(3)
                
        finally:
            driver.quit()
        
        print(f"\n=== å®Œäº† ===")
        print(f"æˆåŠŸ: {success}ä»¶")
        print(f"å¤±æ•—: {failed}ä»¶")


if __name__ == '__main__':
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == 'discover':
        # ç™ºè¦‹ãƒ•ã‚§ãƒ¼ã‚º
        limit = int(sys.argv[2]) if len(sys.argv) > 2 else None
        discover_indeed_pages(limit=limit)
    else:
        # è©³ç´°å–å¾—ãƒ•ã‚§ãƒ¼ã‚º
        scrape_indeed_details()
```

---

## ğŸ¨ ç®¡ç†ç”»é¢UIè¨­è¨ˆ

### 1. å¤–éƒ¨ã‚µã‚¤ãƒˆç®¡ç†ãƒšãƒ¼ã‚¸

```python
# app.py - ç®¡ç†ç”»é¢ãƒ«ãƒ¼ãƒˆè¿½åŠ 

@app.route('/admin/external-sources')
@requires_auth
def admin_external_sources():
    """å¤–éƒ¨ã‚µã‚¤ãƒˆç®¡ç†ç”»é¢"""
    sources = ExternalSource.query.order_by(ExternalSource.priority.desc()).all()
    
    # å„ã‚½ãƒ¼ã‚¹ã®çµ±è¨ˆæƒ…å ±
    source_stats = []
    for source in sources:
        links_count = ExternalLink.query.filter_by(source_id=source.id).count()
        active_count = ExternalLink.query.filter_by(
            source_id=source.id, 
            status='active'
        ).count()
        
        source_stats.append({
            'source': source,
            'total_links': links_count,
            'active_links': active_count,
            'pending_scrape': ExternalLink.query.filter_by(
                source_id=source.id,
                status='pending'
            ).count(),
        })
    
    return render_template('admin/external_sources.html', source_stats=source_stats)


@app.route('/admin/external-sources/add', methods=['GET', 'POST'])
@requires_auth
def admin_add_external_source():
    """å¤–éƒ¨ã‚µã‚¤ãƒˆè¿½åŠ """
    if request.method == 'POST':
        source = ExternalSource(
            name=request.form['name'],
            slug=request.form['slug'],
            category=request.form['category'],
            url_pattern=request.form.get('url_pattern'),
            search_url_template=request.form.get('search_url_template'),
            scraping_enabled=request.form.get('scraping_enabled') == 'on',
            priority=int(request.form.get('priority', 0)),
        )
        db.session.add(source)
        db.session.commit()
        
        flash(f'{source.name} ã‚’è¿½åŠ ã—ã¾ã—ãŸ', 'success')
        return redirect(url_for('admin_external_sources'))
    
    return render_template('admin/external_source_form.html')


@app.route('/admin/external-sources/<int:source_id>/discover', methods=['POST'])
@requires_auth
def admin_discover_external_links(source_id):
    """å¤–éƒ¨ã‚µã‚¤ãƒˆãƒªãƒ³ã‚¯ç™ºè¦‹ã‚¿ã‚¹ã‚¯ä½œæˆ"""
    source = ExternalSource.query.get_or_404(source_id)
    
    # ScrapingTaskä½œæˆ
    task = ScrapingTask(
        task_type='external_source_discovery',
        external_source_id=source_id,
        search_keyword=source.name,
        status='æœªå®Ÿè¡Œ',
        category_id=1,  # é©åˆ‡ãªã‚«ãƒ†ã‚´ãƒªID
    )
    db.session.add(task)
    db.session.commit()
    
    flash(f'{source.name} ã®ç™ºè¦‹ã‚¿ã‚¹ã‚¯ã‚’ä½œæˆã—ã¾ã—ãŸ', 'success')
    return redirect(url_for('admin_external_sources'))


@app.route('/admin/businesses/<int:business_id>/external-links')
@requires_auth
def admin_business_external_links(business_id):
    """ç‰¹å®šãƒ“ã‚¸ãƒã‚¹ã®å¤–éƒ¨ã‚µã‚¤ãƒˆãƒªãƒ³ã‚¯ç®¡ç†"""
    business = Business.query.get_or_404(business_id)
    
    # å…¨å¤–éƒ¨ã‚µã‚¤ãƒˆå–å¾—
    all_sources = ExternalSource.query.filter_by(is_active=True).all()
    
    # ã“ã®ãƒ“ã‚¸ãƒã‚¹ã®æ—¢å­˜ãƒªãƒ³ã‚¯
    existing_links = {link.source_id: link for link in business.external_links}
    
    links_data = []
    for source in all_sources:
        link = existing_links.get(source.id)
        links_data.append({
            'source': source,
            'link': link,
            'has_link': link is not None,
        })
    
    return render_template('admin/business_external_links.html',
                         business=business,
                         links_data=links_data)
```

### 2. ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä¾‹

```html
<!-- templates/admin/external_sources.html -->
{% extends "layout.html" %}

{% block content %}
<div class="max-w-7xl mx-auto px-4 py-8">
  <div class="flex justify-between items-center mb-6">
    <h1 class="text-3xl font-bold">å¤–éƒ¨ã‚µã‚¤ãƒˆç®¡ç†</h1>
    <a href="{{ url_for('admin_add_external_source') }}" 
       class="bg-blue-600 text-white px-4 py-2 rounded hover:bg-blue-700">
      + å¤–éƒ¨ã‚µã‚¤ãƒˆè¿½åŠ 
    </a>
  </div>
  
  <div class="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6">
    {% for stat in source_stats %}
    <div class="bg-white border rounded-lg p-6 shadow-sm">
      <div class="flex items-center justify-between mb-4">
        <h3 class="text-xl font-semibold">{{ stat.source.name }}</h3>
        {% if stat.source.is_active %}
        <span class="bg-green-100 text-green-800 px-2 py-1 rounded text-sm">
          æœ‰åŠ¹
        </span>
        {% else %}
        <span class="bg-gray-100 text-gray-800 px-2 py-1 rounded text-sm">
          ç„¡åŠ¹
        </span>
        {% endif %}
      </div>
      
      <div class="space-y-2 mb-4">
        <div class="flex justify-between text-sm">
          <span class="text-gray-600">ã‚«ãƒ†ã‚´ãƒª:</span>
          <span class="font-medium">{{ stat.source.category }}</span>
        </div>
        <div class="flex justify-between text-sm">
          <span class="text-gray-600">ç™»éŒ²ãƒªãƒ³ã‚¯:</span>
          <span class="font-medium">{{ stat.total_links }}ä»¶</span>
        </div>
        <div class="flex justify-between text-sm">
          <span class="text-gray-600">æœ‰åŠ¹:</span>
          <span class="font-medium text-green-600">{{ stat.active_links }}ä»¶</span>
        </div>
        <div class="flex justify-between text-sm">
          <span class="text-gray-600">ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¾…ã¡:</span>
          <span class="font-medium text-orange-600">{{ stat.pending_scrape }}ä»¶</span>
        </div>
      </div>
      
      <div class="flex space-x-2">
        <form action="{{ url_for('admin_discover_external_links', source_id=stat.source.id) }}" 
              method="POST" class="flex-1">
          <button type="submit" 
                  class="w-full bg-blue-600 text-white px-3 py-2 rounded text-sm hover:bg-blue-700">
            ğŸ” ç™ºè¦‹é–‹å§‹
          </button>
        </form>
        
        {% if stat.pending_scrape > 0 %}
        <button class="bg-orange-600 text-white px-3 py-2 rounded text-sm hover:bg-orange-700">
          ğŸ“¥ å–å¾—é–‹å§‹
        </button>
        {% endif %}
      </div>
    </div>
    {% endfor %}
  </div>
</div>
{% endblock %}
```

### 3. ãƒ“ã‚¸ãƒã‚¹è©³ç´°ãƒšãƒ¼ã‚¸ã«å¤–éƒ¨ã‚µã‚¤ãƒˆè¡¨ç¤º

```html
<!-- templates/clinic/detail.html -->

<!-- åŸºæœ¬æƒ…å ±ã®å¾Œã«è¿½åŠ  -->
<div class="bg-white rounded-lg shadow p-6 mb-6">
  <h2 class="text-2xl font-bold mb-4">å¤–éƒ¨ã‚µã‚¤ãƒˆæƒ…å ±</h2>
  
  <div class="grid grid-cols-2 md:grid-cols-4 gap-4">
    {% for link in business.external_links %}
    {% if link.status == 'active' %}
    <a href="{{ link.url }}" target="_blank" 
       class="border rounded-lg p-4 hover:shadow-md transition">
      <div class="text-center">
        <div class="text-3xl mb-2">
          {% if link.source.slug == 'indeed' %}ğŸ’¼
          {% elif link.source.slug == 'hotpepper' %}ğŸ’†
          {% elif link.source.slug == 'tabelog' %}ğŸ½ï¸
          {% else %}ğŸ”—
          {% endif %}
        </div>
        <div class="font-medium">{{ link.source.name }}</div>
        
        {% if link.scraped_data %}
        <div class="text-sm text-gray-600 mt-2">
          {% if link.scraped_data.get('æ±‚äººæ²è¼‰æ•°') %}
          <div>æ±‚äºº: {{ link.scraped_data['æ±‚äººæ²è¼‰æ•°'] }}ä»¶</div>
          {% endif %}
          {% if link.scraped_data.get('ä¼æ¥­è©•ä¾¡') %}
          <div>è©•ä¾¡: {{ link.scraped_data['ä¼æ¥­è©•ä¾¡'] }}â˜…</div>
          {% endif %}
        </div>
        {% endif %}
      </div>
    </a>
    {% endif %}
    {% endfor %}
  </div>
</div>
```

---

## ğŸš€ å®Ÿè£…ãƒ•ãƒ­ãƒ¼

### Phase 1: åŸºç›¤æ§‹ç¯‰
1. [ ] ãƒ¢ãƒ‡ãƒ«è¿½åŠ ï¼ˆExternalSource, ExternalLinkï¼‰
2. [ ] ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
3. [ ] åˆæœŸå¤–éƒ¨ã‚µã‚¤ãƒˆç™»éŒ²ï¼ˆIndeed, HPBç­‰ï¼‰

### Phase 2: ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å®Ÿè£…
4. [ ] Indeedã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ã‚¹ã‚¯ãƒªãƒ—ãƒˆä½œæˆ
5. [ ] ç™ºè¦‹ãƒ•ã‚§ãƒ¼ã‚ºãƒ†ã‚¹ãƒˆï¼ˆ10ä»¶ï¼‰
6. [ ] è©³ç´°å–å¾—ãƒ•ã‚§ãƒ¼ã‚ºãƒ†ã‚¹ãƒˆï¼ˆ10ä»¶ï¼‰

### Phase 3: ç®¡ç†ç”»é¢æ§‹ç¯‰
7. [ ] å¤–éƒ¨ã‚µã‚¤ãƒˆç®¡ç†ãƒšãƒ¼ã‚¸å®Ÿè£…
8. [ ] ã‚¿ã‚¹ã‚¯å®Ÿè¡Œãƒœã‚¿ãƒ³è¿½åŠ 
9. [ ] é€²æ—è¡¨ç¤ºæ©Ÿèƒ½

### Phase 4: ãƒ•ãƒ­ãƒ³ãƒˆè¡¨ç¤º
10. [ ] ãƒ“ã‚¸ãƒã‚¹è©³ç´°ãƒšãƒ¼ã‚¸ã«å¤–éƒ¨ãƒªãƒ³ã‚¯è¡¨ç¤º
11. [ ] æ¤œç´¢ãƒ•ã‚£ãƒ«ã‚¿è¿½åŠ ï¼ˆIndeedæ²è¼‰ä¼æ¥­ã®ã¿ç­‰ï¼‰

---

## ğŸ“Š å®Ÿè£…å¾Œã®æ¥­å‹™ãƒ•ãƒ­ãƒ¼

```
1. ç®¡ç†ç”»é¢ã§ã€ŒIndeedã€ã®ã€Œç™ºè¦‹é–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚¯ãƒªãƒƒã‚¯
   â†“
2. ScrapingTaskä½œæˆ â†’ ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œ
   â†“
3. 1,722ä»¶ã®ã‚¯ãƒªãƒ‹ãƒƒã‚¯ã‚’Indeedæ¤œç´¢
   â†“
4. ä¼æ¥­ãƒšãƒ¼ã‚¸ç™ºè¦‹ â†’ ExternalLinkä½œæˆï¼ˆstatus='pending'ï¼‰
   â†“
5. ç®¡ç†ç”»é¢ã§ã€Œå–å¾—é–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚¯ãƒªãƒƒã‚¯
   â†“
6. pendingçŠ¶æ…‹ã®ãƒªãƒ³ã‚¯ã‚’ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
   â†“
7. æ±‚äººæ•°ãƒ»è©•ä¾¡ç­‰ã‚’ scraped_data ã«ä¿å­˜ï¼ˆstatus='active'ï¼‰
   â†“
8. ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰è¡¨ç¤º: ãƒ“ã‚¸ãƒã‚¹è©³ç´°ã«ã€ŒIndeedã§æ±‚äººæƒ…å ±ã‚’è¦‹ã‚‹ã€ãƒªãƒ³ã‚¯
```

---

ã“ã®è¨­è¨ˆã§**ã©ã‚“ãªå¤–éƒ¨ã‚µã‚¤ãƒˆã§ã‚‚çµ±ä¸€çš„ã«ç®¡ç†**ã§ãã¾ã™ï¼

å®Ÿè£…ã‚’é–‹å§‹ã—ã¾ã™ã‹ï¼Ÿãã‚Œã¨ã‚‚ç‰¹å®šã®å¤–éƒ¨ã‚µã‚¤ãƒˆï¼ˆIndeedç­‰ï¼‰ã®è©³ç´°è¨­è¨ˆã‚’å…ˆã«è©°ã‚ã¾ã™ã‹?